{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c69c26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "620d172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataSet(directory, tokenizer, train_ratio):\n",
    "    files = os.listdir(directory)\n",
    "    random.shuffle(files)\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    x_validation=[]\n",
    "    y_validation=[]\n",
    "    for f in files[:int(train_ratio*len(files))]:\n",
    "        pil=tf.keras.utils.load_img(os.path.join(directory,f),color_mode='grayscale')\n",
    "        npArray = tf.keras.utils.img_to_array(pil)/255.\n",
    "        x_train.append(npArray)\n",
    "        y_train.append(f[:-4])\n",
    "    for f in files[int(train_ratio*len(files)):]:\n",
    "        pil=tf.keras.utils.load_img(os.path.join(directory,f),color_mode='grayscale')\n",
    "        npArray = tf.keras.utils.img_to_array(pil)/255.\n",
    "        x_validation.append(npArray)\n",
    "        y_validation.append(f[:-4])\n",
    "    return np.array(x_train), np.array(y_train), np.array(x_validation), np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9ab390b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "directory = \"CAPTCHA\"\n",
    "files = os.listdir(directory)\n",
    "random.shuffle(files)\n",
    "\n",
    "labels = []\n",
    "\n",
    "for i in files:\n",
    "    labels.append(i[:-4])\n",
    "\n",
    "    \n",
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(char_level=True, oov_token = \"NA\")\n",
    "\n",
    "tokenizer.fit_on_texts(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94d00552",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = .9 \n",
    "batch_size = 32\n",
    "#xt,yt,xv,yv = makeDataSet(directory,tokenizer,.9)\n",
    "xt = []\n",
    "yt = []\n",
    "xv = []\n",
    "yv = []\n",
    "for i in files[:int(len(files)*split_ratio)]:\n",
    "    xt.append(os.path.join(directory,i))\n",
    "    yt.append(tokenizer.texts_to_sequences(i[:-4]))\n",
    "for i in files[int(len(files)*split_ratio):]:\n",
    "    xv.append(os.path.join(directory,i))\n",
    "    yv.append(tokenizer.texts_to_sequences(i[:-4]))\n",
    "\n",
    "def encode_sample(img_path, label): \n",
    "    img = tf.io.read_file(img_path) \n",
    "    img = tf.io.decode_png(img, channels=1) \n",
    "    img = tf.image.convert_image_dtype(img, tf.float32) \n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\n",
    "    img = tf.image.resize(img, [150, 40]) \n",
    "    return {\"image\": img, \"label\": label} \n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((xt, yt)) \n",
    "dataset_train = (dataset_train.map(encode_sample, num_parallel_calls=tf.data.AUTOTUNE) .batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE) ) \n",
    "\n",
    "dataset_validation = tf.data.Dataset.from_tensor_slices((xv, yv))\n",
    "dataset_validation = (dataset_validation.map(encode_sample, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "class CTCLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, name = None):\n",
    "        super().__init__(name = name)\n",
    "        self.loss_fn = tf.keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype = \"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype = \"int64\")\n",
    "        input_length = input_length * tf.ones(shape = (batch_len,1), dtype = \"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype = \"int64\")\n",
    "        label_length = label_length * tf.ones(shape = (batch_len,1), dtype = \"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, \n",
    "                            input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "        return y_pred\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54dac1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img = tf.keras.layers.Input(shape = (150, 40, 1), \n",
    "                               name = \"image\", dtype = \"float32\")\n",
    "labels = tf.keras.layers.Input(name = \"label\", \n",
    "               shape = (None,), dtype = \"float32\")\n",
    "x=tf.keras.layers.Conv2D(32, (3,3), activation ='relu')(input_img)\n",
    "x=tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "x=tf.keras.layers.Conv2D(64, (3,3), activation = 'relu')(x)\n",
    "x=tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "x = tf.keras.layers.Reshape(target_shape = ((36), 8*64))(x)\n",
    "x=tf.keras.layers.Dense(512, activation ='relu')(x)\n",
    "x=tf.keras.layers.Dropout(.5)(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences = True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))(x)\n",
    "x=tf.keras.layers.Dense(512, activation ='relu')(x)\n",
    "x=tf.keras.layers.Dense(len(tokenizer.get_config()['word_index'])+1, activation ='softmax', name = 'output')(x)\n",
    "output=CTCLayer(name = \"ctc_loss\")(labels,x)\n",
    "model = tf.keras.models.Model(\n",
    "        inputs=[input_img, labels], outputs=output\n",
    "    )\n",
    "model.compile(optimizer = 'adam')\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8329cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 79/563 [===>..........................] - ETA: 1:11 - loss: 31.2658"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            dataset_train,\n",
    "            validation_data=dataset_validation,\n",
    "            epochs=100,\n",
    "            callbacks=[callback]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decodeResult(code):\n",
    "    results = []\n",
    "    for label in code:\n",
    "        results.append(tokenizer.sequences_to_texts(np.argmax(code,0))) \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af56bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predModel = tf.keras.models.Model(model.input[0], model.get_layer(name='output').output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model = keras.models.Model(\n",
    "    model.input[0], model.get_layer(name=\"output\").output\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decode(y_pred):\n",
    "    input_shape = tf.shape(y_pred)\n",
    "    input_len = np.ones(y_pred.shape[0]) * y_pred.shape[1]\n",
    "    y_pred = tf.math.log(tf.transpose(y_pred, perm=[1, 0, 2]) + keras.backend.epsilon())\n",
    "    (decoded, log_prob) = tf.nn.ctc_greedy_decoder(inputs=y_pred, sequence_length=tf.cast(input_len, tf.int32))\n",
    "    st = tf.SparseTensor(decoded[0].indices, decoded[0].values, (input_shape[0], input_shape[1]))\n",
    "    st = tf.sparse.to_dense(sp_input=st, default_value=-1)\n",
    "    return st\n",
    "\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = ctc_decode(pred)[:,:5]\n",
    "    output_text = []\n",
    "    for ans in results:\n",
    "        listfyied = [tf.make_ndarray(tf.make_tensor_proto(ans)).tolist()]\n",
    "        ans_char = tf.strings.reduce_join(tokenizer.sequences_to_texts(listfyied)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(ans_char)\n",
    "    return output_text\n",
    "\n",
    "\n",
    "#  Let's check results on some validation samples\n",
    "for batch in dataset_validation.take(1):\n",
    "    batch_images = batch[\"image\"]\n",
    "    batch_labels = batch[\"label\"]\n",
    "    preds = prediction_model.predict(batch_images)\n",
    "    pred_texts = decode_batch_predictions(preds)\n",
    "    \n",
    "    image_num = 0\n",
    "    for label in pred_texts:\n",
    "        listfyied = [tf.make_ndarray(tf.make_tensor_proto(label)).tolist()]\n",
    "        ans_char = tf.strings.reduce_join(tokenizer.sequences_to_texts(listfyied)).numpy().decode(\"utf-8\")\n",
    "        #PIL.Image.fromarray(batch_images[0])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(tf.transpose(batch_images[image_num],perm=[1, 0, 2])),cmap='gray')\n",
    "        plt.show()\n",
    "        print(ans_char)\n",
    "        image_num +=1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad5772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798a421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72d290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf8a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86ced5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
